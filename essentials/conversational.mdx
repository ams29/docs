---
title: 'Conversational & Agent Data'
description: 'Training data for dialogue systems and autonomous agents'
icon: 'comments'
---

## Conversational Training Data

Dialogue data teaches models natural human interaction patterns, enabling them to engage in coherent, contextually appropriate conversations. This data type is essential for creating chatbots, virtual assistants, and interactive AI systems.

<Note>
Conversational data differs from standard instruction-following data by capturing the dynamic, multi-turn nature of human dialogue.
</Note>

## Sources of Conversational Data

<CardGroup cols={3}>
<Card title="Live Interactions" icon="users">
  - Customer service chats
  - Support ticket threads
  - User feedback sessions
  - Real chatbot conversations
</Card>

<Card title="Public Datasets" icon="database">
  - Reddit conversations
  - Twitter threads
  - Forum discussions
  - Movie dialogues
</Card>

<Card title="Custom Creation" icon="pen">
  - Scripted dialogues
  - Role-playing scenarios
  - Synthetic conversations
  - Expert demonstrations
</Card>
</CardGroup>

## Conversation Types and Structures

### Single-Turn Interactions

Isolated prompt-response pairs ideal for initial training:

<CodeGroup>
```json Factual Question
{
  "user": "What's the weather like in Tokyo?",
  "assistant": "I don't have access to real-time weather data. To get current weather information for Tokyo, I recommend checking a weather service like weather.com or your local weather app.",
  "metadata": {
    "type": "factual_query",
    "requires_real_time": true
  }
}
```

```json Coding Task
{
  "user": "Write a Python function to reverse a string",
  "assistant": "Here's a Python function to reverse a string:\n\n```python\ndef reverse_string(s):\n    return s[::-1]\n\n# Example usage:\nprint(reverse_string('hello'))  # Output: 'olleh'\n```",
  "metadata": {
    "type": "code_generation",
    "language": "python"
  }
}
```

```json Translation
{
  "user": "Translate 'Good morning' to Spanish",
  "assistant": "Buenos d√≠as",
  "metadata": {
    "type": "translation",
    "source_lang": "en",
    "target_lang": "es"
  }
}
```
</CodeGroup>

### Multi-Turn Conversations

Extended exchanges capturing realistic interaction patterns:

<Tabs>
<Tab title="Support Conversation">
```json
{
  "conversation_id": "support_12345",
  "turns": [
    {
      "role": "user",
      "content": "My application keeps crashing when I try to export files"
    },
    {
      "role": "assistant",
      "content": "I'm sorry to hear you're experiencing crashes. Let me help you troubleshoot. What type of files are you trying to export?"
    },
    {
      "role": "user",
      "content": "PDF files, usually around 50-100 pages"
    },
    {
      "role": "assistant",
      "content": "Large PDF exports can be memory-intensive. Let's try a few solutions:\n1. First, can you check how much free memory your system has?\n2. Try exporting smaller batches (10-20 pages)\n3. Update to the latest version if you haven't already\n\nWhich would you like to try first?"
    }
  ],
  "metadata": {
    "category": "technical_support",
    "resolution": "pending"
  }
}
```
</Tab>

<Tab title="Interactive Learning">
```json
{
  "conversation_id": "learning_session_789",
  "turns": [
    {
      "role": "user",
      "content": "Can you explain machine learning to me?"
    },
    {
      "role": "assistant",
      "content": "I'd be happy to explain machine learning! Think of it as teaching computers to learn from examples, rather than programming them with specific rules. Would you like me to start with a simple analogy?"
    },
    {
      "role": "user",
      "content": "Yes, an analogy would help"
    },
    {
      "role": "assistant",
      "content": "Imagine teaching a child to recognize cats. Instead of describing every possible cat, you show them many pictures of cats and non-cats. Over time, they learn to identify patterns. Machine learning works similarly - algorithms find patterns in data to make predictions. What aspect would you like to explore further?"
    },
    {
      "role": "user",
      "content": "How does it actually find these patterns?"
    }
  ]
}
```
</Tab>

<Tab title="Role-Based Dialogue">
```json
{
  "conversation_id": "roleplay_456",
  "context": "User wants to practice job interview",
  "turns": [
    {
      "role": "user",
      "content": "I'd like to practice for a software engineering interview"
    },
    {
      "role": "assistant",
      "content": "Great! I'll act as an interviewer. Let's start with a common question: Can you tell me about yourself and your background in software engineering?"
    },
    {
      "role": "user",
      "content": "I have 3 years of experience in full-stack development..."
    }
  ],
  "metadata": {
    "scenario": "job_interview",
    "difficulty": "intermediate"
  }
}
```
</Tab>
</Tabs>

## Workflow for Conversational Data Creation

A typical workflow might begin with annotator-created instruction pairs for initial training, then incorporate user preference data from deployed systems for continuous improvement through RLHF:

<Steps>
<Step title="Initial Dataset Creation">
Create seed conversations covering core scenarios:
- Common user intents
- Edge cases
- Error handling
- Topic transitions
</Step>

<Step title="Deployment and Collection">
Deploy initial model and collect real interactions:
- User conversations
- Success/failure signals
- Engagement metrics
- Preference indicators
</Step>

<Step title="Data Processing">
Clean and annotate collected conversations:
- Remove PII
- Filter quality
- Label intents
- Mark successful patterns
</Step>

<Step title="Iterative Improvement">
Use processed data for model updates:
- Fine-tune on successful conversations
- RLHF on preference data
- Address failure modes
- Expand capabilities
</Step>
</Steps>

## Supporting Autonomous Agent Development

Agent-based systems require specialized data to enable autonomous task execution. Unlike traditional conversational AI, agents must plan, execute, and adapt to achieve complex goals.

<Info>
Agent training data focuses on decision-making, tool usage, and multi-step reasoning rather than just conversation.
</Info>

### Key Data Categories for Agents

<CardGroup cols={2}>
<Card title="Planning Capabilities" icon="route">
  Teaching workflow decomposition, adaptive replanning, task delegation, and self-evaluation
</Card>

<Card title="Task Execution" icon="play">
  Improving specific skills like tool usage, code generation, and information synthesis
</Card>

<Card title="Extended Interactions" icon="clock">
  Training on lengthy exchanges to maintain context and coherence over time
</Card>

<Card title="User Preferences" icon="user-check">
  Collecting feedback on intermediate steps and final outputs
</Card>
</CardGroup>

### Agent Training Data Examples

<AccordionGroup>
<Accordion title="Task Decomposition">
```json
{
  "task": "Create a monthly financial report",
  "plan": [
    {
      "step": 1,
      "action": "Gather financial data from all departments",
      "tools": ["database_query", "spreadsheet_reader"],
      "dependencies": []
    },
    {
      "step": 2,
      "action": "Calculate key metrics (revenue, expenses, profit)",
      "tools": ["calculator", "data_analyzer"],
      "dependencies": [1]
    },
    {
      "step": 3,
      "action": "Create visualizations for trends",
      "tools": ["chart_generator"],
      "dependencies": [2]
    },
    {
      "step": 4,
      "action": "Write executive summary",
      "tools": ["text_generator"],
      "dependencies": [2, 3]
    }
  ],
  "evaluation_criteria": {
    "completeness": "All sections included",
    "accuracy": "Calculations verified",
    "clarity": "Easy to understand"
  }
}
```
</Accordion>

<Accordion title="Tool Usage">
```json
{
  "scenario": "Research competitor pricing",
  "actions": [
    {
      "thought": "I need to find current pricing for top 5 competitors",
      "action": "web_search",
      "action_input": "SaaS project management tool pricing 2024",
      "observation": "Found pricing pages for Asana, Monday, Trello..."
    },
    {
      "thought": "I should extract specific pricing tiers",
      "action": "web_scrape",
      "action_input": "https://asana.com/pricing",
      "observation": "Basic: $10.99/user, Premium: $24.99/user..."
    },
    {
      "thought": "Now I'll compile this into a comparison table",
      "action": "create_table",
      "action_input": {"headers": ["Tool", "Basic", "Premium", "Enterprise"], "data": [...]}
    }
  ]
}
```
</Accordion>

<Accordion title="Error Recovery">
```json
{
  "scenario": "API call failure during data retrieval",
  "initial_action": {
    "type": "api_call",
    "endpoint": "/api/v1/users",
    "result": "error_timeout"
  },
  "recovery_steps": [
    {
      "analysis": "API timeout detected, might be temporary",
      "action": "retry with exponential backoff",
      "max_retries": 3
    },
    {
      "analysis": "Still failing after retries",
      "action": "check alternative endpoints",
      "fallback": "/api/v2/users"
    },
    {
      "analysis": "No API access available",
      "action": "use cached data with warning",
      "notification": "Using data from 2 hours ago"
    }
  ]
}
```
</Accordion>
</AccordionGroup>

## Post-Deployment Data Collection

Post-deployment data proves invaluable for continuous improvement:

<Tabs>
<Tab title="SFT Examples">
Creating training examples from real interactions:
- Successful task completions
- Corrected failure cases
- Novel user requests
- Improved responses
</Tab>

<Tab title="Model Evaluations">
Developing targeted assessments:
- Task-specific benchmarks
- Failure mode detection
- Performance regression tests
- Capability boundaries
</Tab>

<Tab title="System Tests">
Building comprehensive test suites:
- End-to-end workflows
- Integration tests
- Load testing scenarios
- Edge case coverage
</Tab>

<Tab title="Preference Data">
Gathering alignment signals:
- User satisfaction ratings
- A/B test results
- Implicit feedback
- Behavioral metrics
</Tab>
</Tabs>

## Critical Considerations for Multi-Step Workflows

<Warning>
Given the compound nature of multi-step workflows, thorough evaluation at each stage becomes critical for system reliability.
</Warning>

### Evaluation Strategy for Agents

<Steps>
<Step title="Component Testing">
Test individual capabilities:
- Tool usage accuracy
- Planning logic
- Error handling
- Context retention
</Step>

<Step title="Integration Testing">
Verify component interactions:
- Tool chaining
- State management
- Resource handling
- Failure propagation
</Step>

<Step title="End-to-End Validation">
Test complete workflows:
- Task completion rates
- Time efficiency
- Resource usage
- Output quality
</Step>

<Step title="Human-in-the-Loop Testing">
Validate with real users:
- Usability studies
- Preference collection
- Failure analysis
- Improvement suggestions
</Step>
</Steps>

## Data Quality Guidelines

### Conversation Quality Metrics

| Metric | Description | Target |
|--------|-------------|--------|
| Coherence | Logical flow between turns | >90% |
| Relevance | On-topic responses | >95% |
| Completeness | Full information provided | >85% |
| Natural Flow | Human-like interaction | >80% |

### Agent Performance Metrics

| Metric | Description | Target |
|--------|-------------|--------|
| Task Success | Completed objectives | >75% |
| Efficiency | Steps vs optimal | <1.5x |
| Error Recovery | Handled failures | >90% |
| User Satisfaction | Positive feedback | >80% |

## Best Practices for Conversational and Agent Data

<AccordionGroup>
<Accordion title="Diversity and Coverage">
Ensure comprehensive scenarios:
- Multiple domains and topics
- Various user personas
- Different conversation styles
- Edge cases and failures
- Cultural considerations
</Accordion>

<Accordion title="Quality Control">
Implement rigorous standards:
- Annotation guidelines
- Quality review process
- Consistency checks
- Performance validation
- Regular audits
</Accordion>

<Accordion title="Privacy and Ethics">
Protect user information:
- PII removal
- Consent protocols
- Data anonymization
- Secure storage
- Access controls
</Accordion>

<Accordion title="Continuous Improvement">
Maintain data freshness:
- Regular updates
- Trend monitoring
- Performance tracking
- User feedback integration
- Capability expansion
</Accordion> 